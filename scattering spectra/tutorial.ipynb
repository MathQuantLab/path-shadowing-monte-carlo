{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scatspectra.frontend import (\n",
    "    load_data,\n",
    "    analyze,\n",
    "    generate,\n",
    "    plot_raw,\n",
    "    plot_dashboard,\n",
    "    plot_marginal_moments,\n",
    "    plot_phase_envelope_spectrum,\n",
    ")\n",
    "from scatspectra.data_source import SPDaily\n",
    "from scatspectra.layers.filter_bank import init_band_pass, init_low_pass\n",
    "from scatspectra.layers.statistics import TimeAverage, AvgPooling, WindowSelector\n",
    "\n",
    "CACHE_PATH = Path(os.getcwd()) / \"_cache\"\n",
    "CACHE_PATH.mkdir(exist_ok=True)\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "if not CUDA:\n",
    "    print(\"CUDA is not available: some computations will be slowed-down\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analysis of time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function \"load_data\" provides data from standard models as well as historical data of SP500\n",
    "\n",
    "# Brownian motion\n",
    "x_brownian = load_data(\n",
    "    name=\"fbm\",\n",
    "    R=128,\n",
    "    T=6063,  # 1 realization of 6063 time-steps\n",
    "    H=0.5,  # Hurst exponent, 0.5 for Brownian motion\n",
    "    cache_path=CACHE_PATH,\n",
    ")\n",
    "dx_brownian = np.diff(x_brownian, axis=-1)\n",
    "\n",
    "# Multifractal Random Walk\n",
    "x_mrw = load_data(\n",
    "    name=\"mrw\",\n",
    "    R=128,\n",
    "    T=6063,\n",
    "    H=0.5,  # means no auto-correlation\n",
    "    lam=0.2,\n",
    "    cache_path=CACHE_PATH,\n",
    ")\n",
    "dx_mrw = np.diff(x_mrw, axis=-1)\n",
    "\n",
    "# historical daily prices of SP500 from 03-01-2000 to 07-02-2024\n",
    "data_snp = SPDaily()  # single time-series\n",
    "\n",
    "################ plotting ####################################\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Financial (log-returns) time-series\", fontsize=20)\n",
    "axes[0].plot(dx_brownian[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_ylabel(f\"Brown.\", fontsize=15)\n",
    "axes[1].plot(dx_mrw[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[1].set_xticklabels([])\n",
    "axes[1].set_ylabel(f\"MRW\", fontsize=15)\n",
    "axes[2].plot(data_snp.dts[:-1], data_snp.dlnx[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[2].set_ylabel(f\"S&P\", fontsize=15)\n",
    "for ax in axes:\n",
    "    ylim = 0.04\n",
    "    ax.set_ylim(-ylim, ylim)\n",
    "    ax.grid(True)\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: 'analyze'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 'analyze' computes wavelet-based statistics, e.g. Scattering Spectra:\n",
    "\n",
    "# Scattering Spectra of S&500\n",
    "scat_snp = analyze(\n",
    "    x=data_snp.dlnx,\n",
    "    model_type=\"scat_spectra\",\n",
    "    J=6,  # number of scales (see next cells)\n",
    ")\n",
    "\n",
    "# Scattering Spectra of white noise: for comparison\n",
    "scat_wn = analyze(\n",
    "    x=dx_brownian,\n",
    "    model_type=\"scat_spectra\",\n",
    "    J=6,  # number of scales (see next cells)\n",
    ")\n",
    "\n",
    "################ plotting ####################################\n",
    "# quick plot\n",
    "print(\"Row visualization of Scattering Spectra.\")\n",
    "print(\"See 'Visualization' for a better visualization.\")\n",
    "ax1, _ = plot_raw(scat_snp, legend=True)\n",
    "ax1.set_title(\"Scattering Spectra of S&P500 (raw visualization)\", fontsize=12)\n",
    "ax2, _ = plot_raw(scat_wn, legend=False)\n",
    "ax2.set_title(\"Scattering Spectra of white noise (raw visualization)\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful methods. See class DescribedTensor for more methods\n",
    "print(\n",
    "    f\"Scattering Spectra shape: \\n{scat_snp.y.shape} \\n\"\n",
    ")  # batch_size x num_coeffs x num_times (num_times=1 because time has been averaged)\n",
    "print(f\"Scattering Spectra description shape: \\n{scat_snp.df.shape}\\n\")\n",
    "\n",
    "# Each coefficient scat_snp.y[:,i,:] is described by the row scat_snp.df.iloc[i]\n",
    "# For example:\n",
    "i = 15\n",
    "print(\n",
    "    f\"Coefficient {i} is equal to \\n{scat_snp.y[0,i,0]:.3f}\\nand its description is \\n\\n{scat_snp.df.iloc[i]}\\n\"\n",
    ")\n",
    "\n",
    "# some additional information\n",
    "# 'coeff_type': the coefficient type e.g. spars, variance, skewness, kurtosis\n",
    "# 'nl': (for multi-variate analysis) the in-channel index of the left-term in a correlation\n",
    "# 'nr': (for multi-variate analysis) the in-channel index of the right-term in a correlation\n",
    "# 'q': the order of the moment: 1 for the mean or sparsity factors, 2 for the correlation coefficients (variance, skewness, kurtosis)\n",
    "# 'rl': the scattering order (number of convolutions) of the left-hand term in a correlation\n",
    "# 'rr': the scattering order (number of convolutions) of the right-hand term in a correlation\n",
    "# 'scl': the unique scattering index of the scale path (jl1,j2) of the left-hand term in a correlation\n",
    "# 'scr': the unique scattering index of the scale path (jr1,j2) of the right-hand term in a correlation\n",
    "# 'jl1': the scale index of the first wavelet of the left-hand term in a correlation\n",
    "# 'jr1': the scale index of the first wavelet of the right-hand term in a correlation\n",
    "# 'j2': the scale index of the second wavelet in a correlation\n",
    "# 'al': (for image data) the angle of the first wavelet of the left-hand term in a correlation\n",
    "# 'ar': (for image data) the angle of the first wavelet of the right-hand term in a correlation\n",
    "# 'is_low': whether this is a low-pass coefficient: the last wavelet corresponds to a low-pass filter\n",
    "\n",
    "# to access coefficients by their description:\n",
    "# for example, accessing a skewness coefficients at scale j=2\n",
    "print(\"Coefficient selection\")\n",
    "selected_coeff = scat_snp.query(\n",
    "    coeff_type=\"skewness\", jl1=2, jr1=2\n",
    ")  # DescribedTensor object\n",
    "print(selected_coeff.df)\n",
    "print(selected_coeff.y[0, 0, 0].item(), \"\\n\")\n",
    "# other example: selecting the sparsity and variance coefficients\n",
    "selected_coeff = scat_snp.query(coeff_type=[\"spars\", \"variance\"])\n",
    "print(selected_coeff.df)\n",
    "print(selected_coeff.y[0, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "For a Scattering Spectra representation, function \"plot_dashboard\" separates the different coefficients \\\n",
    "and visualize them as 'spectra', as curves along scales.\n",
    "- 'mean' (1 coeff): the time-average of x: $<x(t)>_t$\n",
    "- 'spars' (~J coeffs): the sparsity factor of wavelet coefficients at each scale: $<|x\\star\\psi_j(t)|>_t / \\sigma_j$\n",
    "- 'variance' (~J coeffs): the variance, or energy, of wavelet coefficients at each scale: $\\sigma^2_j = <|x\\star\\psi_j(t)|^2>_t$\n",
    "- 'skewness' (~J^2/2 coeffs): the cross-scale correlations $<x\\star\\psi_{j_l}(t)~|x\\star\\psi_{j_r}(t)|> / (\\sigma_{j_l} \\sigma_{j_r})$\n",
    "- 'kurtosis' (~J^3/6 coeffs): the cross-scale correlations $<|x\\star\\psi_{j_l}|*\\psi_{j_2}(t)~|x\\star\\psi_{j_r}(t)|\\star\\psi^*_{j_2}(t)> / (\\sigma_{j_l} \\sigma_{j_r})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plot_dashboard(\n",
    "    [scat_wn, scat_snp],\n",
    "    labels=[\"White noise\", \"S&P500\"],\n",
    "    theta_threshold=[0.3, 0.1],  # avoid complex-phase instabilities\n",
    "    figsize=(12, 6),\n",
    ")\n",
    "for ax in [axes[0, 1], axes[1, 0]]:\n",
    "    ax.legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Can be found in the paper \"Scale Dependencies and Self-Similar Models with Wavelet Scattering Spectra\" https://arxiv.org/abs/2204.10177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sparsity $\\Phi_1$, variance $\\Phi_2$\n",
    "\n",
    "'variance' coefficients: the standard power spectrum $\\sigma^2_j = <|x\\star\\psi_j(t)|^2>_t$\n",
    "\\\n",
    "The power-spectrum of both white noise and S&P500 is flat, as expected:\n",
    "these time-series are uncorrelated over time.\n",
    "\n",
    "'sparsity' coefficients: sparsity at different scales $<|x\\star\\psi_j(t)|>_t / \\sigma_j$\n",
    "\\\n",
    "The level and decay of the curve quantifies intermittency: the lower and the steeper\n",
    "the curve, the more sparsity. \\\n",
    "For a Gaussian, this curve is flat, at a high level. \n",
    "For a financial time-series which presents intermittency, e.g. crisis, \n",
    "this curve is low and decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(3, 7))\n",
    "plot_marginal_moments([scat_wn, scat_snp], labels=[\"White noise\", \"S&P500\"], axes=axes)\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_xlabel((\"\"))\n",
    "axes[0].legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skewness $\\Phi_3$\n",
    "\n",
    "Skewness coefficients: $<x\\star\\psi_{j_l}(t)~|x\\star\\psi_{j_r}(t)|> / (\\sigma_{j_l} \\sigma_{j_r})$\n",
    "\n",
    "Their modulus quantify the change in $x$ when its sign is changed $-x$. \\\n",
    "A 'skewed' process breaks the sign invariance $x$-> $-x$. \\\n",
    "The larger their modulus the more 'skewed' the process is.\n",
    "\n",
    "Their complex-phase quantifies time-asymmetry that is the change in the \\\n",
    "process $x$ when the time is reversed $x(-t)$. \\\n",
    "A non-zero phase indicates time-asymmetry.\n",
    "\n",
    "A Gaussian process is invariant to sign-change and time-reversal, thus, both \n",
    "curves are zero. \n",
    "\n",
    "The financial time-series is skewed as shown on the graph of $\\Phi_3$. \\\n",
    "It has also time-asymmetries, as shown on the graph of Arg $\\Phi_3$. \\ \n",
    "Both are expected -- this is the leverage effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(3, 7))\n",
    "plot_phase_envelope_spectrum(\n",
    "    [scat_wn, scat_snp], labels=[\"White noise\", \"S&P500\"], axes=axes\n",
    ")\n",
    "axes[0].set_xticklabels([])\n",
    "axes[0].set_xlabel((\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the averaging operator\n",
    "\n",
    "Scattering Spectra are estimated by averaging over the time dimension. \\\n",
    "Other operators are available such as average pooling. \\\n",
    "They can be provided through the 'estim_operator' argument in 'analyze' function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: Scattering Spectra statistics averaged on the full window\n",
    "estim_operator = None\n",
    "scat_wn = analyze(\n",
    "    x=np.random.randn(1024),\n",
    "    model_type=\"scat_spectra\",\n",
    "    estim_operator=None,\n",
    ")\n",
    "print(\"Output time shape\", scat_wn.y.shape[-1])\n",
    "\n",
    "# window selection: Scattering Spectra at each time: no average\n",
    "window = np.arange(12, 1024 - 12)\n",
    "estim_operator = WindowSelector(window=window)\n",
    "scat_wn = analyze(\n",
    "    x=np.random.randn(1024), model_type=\"scat_spectra\", estim_operator=estim_operator\n",
    ")\n",
    "print(\"Output time shape\", scat_wn.y.shape[-1])\n",
    "\n",
    "# average on a given window e.g. the middle 512 samples\n",
    "estim_operator = TimeAverage(window=window)\n",
    "scat_wn = analyze(\n",
    "    x=np.random.randn(1024), model_type=\"scat_spectra\", estim_operator=estim_operator\n",
    ")\n",
    "print(\"Output time shape\", scat_wn.y.shape[-1])\n",
    "\n",
    "# average pooling\n",
    "estim_operator = AvgPooling(kernel_size=2, stride=2)\n",
    "scat_wn = analyze(\n",
    "    x=np.random.randn(1024), model_type=\"scat_spectra\", estim_operator=estim_operator\n",
    ")\n",
    "print(\"Output time shape\", scat_wn.y.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the hyper-parameters\n",
    "\n",
    "Every parameter of 'analyze' admits a default value so that the only parameter\n",
    "to provide is the data to analyze.\n",
    "\n",
    "However, if you want to explore changes in the wavelet parameter, \n",
    "the generative algorithm etc ... here are some guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wavelet parameters high_freq, J, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the wavelet filters\n",
    "\n",
    "\n",
    "def get_wavelets_psi(T, J, Q, wav_type, high_freq):\n",
    "    psi_hat = torch.tensor(init_band_pass(wav_type, T, J, Q, high_freq, wav_norm=\"l1\"))\n",
    "    psi = torch.fft.ifft(psi_hat)\n",
    "    psi = torch.roll(psi, shifts=(psi.shape[-1] // 2,), dims=(-1,))\n",
    "    return psi, psi_hat\n",
    "\n",
    "\n",
    "def get_wavelet_phi(T, J, Q, wav_type, high_freq):\n",
    "    phi_hat = torch.tensor(init_low_pass(wav_type, T, J, Q, high_freq))\n",
    "    phi = torch.fft.ifft(phi_hat)\n",
    "    phi = torch.roll(phi, shifts=(phi.shape[-1] // 2,), dims=(-1,))\n",
    "    return phi, phi_hat\n",
    "\n",
    "\n",
    "T = 128\n",
    "J = 4\n",
    "\n",
    "filter, psi_hat = get_wavelets_psi(\n",
    "    T, J=J, Q=1, wav_type=\"battle_lemarie\", high_freq=0.425\n",
    ")\n",
    "freq = torch.fft.fftfreq(T)\n",
    "\n",
    "################ plotting ####################################\n",
    "_, axes = plt.subplots(J, 2, figsize=(10, 6))\n",
    "axes[0, 0].set_title(\"time domain\")\n",
    "axes[0, 1].set_title(\"Fourier domain\")\n",
    "axes[0, 1].plot(torch.fft.fftshift(freq), torch.fft.fftshift(psi_hat, dim=-1).real.T)\n",
    "axes[0, 1].grid(True)\n",
    "axes[-1, 0].set_xlabel(\"$t$\")\n",
    "axes[0, 1].set_xlabel(\"$\\omega$\")\n",
    "# axes[0,1].axvline(filt_hat.shape[1]//2, color='black')\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "for j in range(J):\n",
    "    color = colors[j % len(colors)]\n",
    "    axes[j, 0].plot(filter[j, :].real, color=color)\n",
    "    axes[j, 0].set_ylabel(f\"j={j}\", fontsize=15)\n",
    "    if j > 0:\n",
    "        axes[j, 1].remove()\n",
    "    if j < J - 1:\n",
    "        axes[j, 0].set_xticklabels([])\n",
    "    if j < J:\n",
    "        axes[j, 0].set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 'high_freq'\n",
    "# the central frequency of the mother wavelet\n",
    "# 0.0 < high_freq < 0.5, default=0.425 for \"battle_lemarie\" wavelets\n",
    "\n",
    "# the choice of high_freq is ruled by the following trade-off\n",
    "# 1. the energy of the mother wavelet on negative frequencies should be\n",
    "# as small as possible (because this breaks the fact that other band-pass filters\n",
    "# are obtained by dilation)\n",
    "# 2. the mother wavelet should cover high-frequency (omega~<0.5)\n",
    "\n",
    "# we consistently take high_freq=0.425 for battle-lemarie wavelets:\n",
    "# below:\n",
    "# high_freq=0.25: high-frequencies are partially covered\n",
    "# high_freq=0.425: small aliasing and high-frequencies are covered\n",
    "# high_freq=0.5: too much aliasing\n",
    "\n",
    "T = 2048\n",
    "\n",
    "high_freqs = [0.25, 0.425, 0.5]\n",
    "psis_hat = [\n",
    "    get_wavelets_psi(T, J=8 - 4, Q=1, wav_type=\"battle_lemarie\", high_freq=high_freq)[1]\n",
    "    for high_freq in high_freqs\n",
    "]\n",
    "freqs = torch.fft.fftfreq(T)\n",
    "\n",
    "################ plotting ####################################\n",
    "fig, axes = plt.subplots(len(high_freqs), 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Mother wavelet (fourier domain)\")\n",
    "axes[-1].set_xlabel(\"$\\omega$\")\n",
    "axes[0].text(\n",
    "    -0.4,\n",
    "    0.95,\n",
    "    \"aliasing\",\n",
    "    color=\"gray\",\n",
    "    transform=axes[0].get_xaxis_transform(),\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    ")\n",
    "axes[0].text(\n",
    "    0.4,\n",
    "    0.95,\n",
    "    \"high frequencies\",\n",
    "    color=\"gray\",\n",
    "    transform=axes[0].get_xaxis_transform(),\n",
    "    ha=\"center\",\n",
    "    va=\"top\",\n",
    ")\n",
    "for i in range(len(high_freqs)):\n",
    "    if i < 2:\n",
    "        axes[i].set_xticklabels([])\n",
    "    axes[i].axvline(0.0, color=\"black\", lw=0.4)\n",
    "    axes[i].plot(\n",
    "        torch.fft.fftshift(freqs),\n",
    "        torch.fft.fftshift(psis_hat[i][1:, :], dim=-1).real.T,\n",
    "        color=\"pink\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        torch.fft.fftshift(freqs),\n",
    "        torch.fft.fftshift(psis_hat[i][0, :], dim=-1).real,\n",
    "        label=f\"high_freq={high_freqs[i]}\",\n",
    "    )\n",
    "    axes[i].axvline(high_freqs[i], color=\"red\")\n",
    "    axes[i].text(\n",
    "        high_freqs[i],\n",
    "        0.0,\n",
    "        f\"high_freq={high_freqs[i]}\",\n",
    "        color=\"red\",\n",
    "        transform=axes[i].get_xaxis_transform(),\n",
    "        ha=\"center\",\n",
    "        va=\"top\",\n",
    "    )\n",
    "    axes[i].axvspan(-0.5, -0.3, color=\"black\", alpha=0.1)\n",
    "    axes[i].axvspan(0.3, 0.5, color=\"black\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 'J'\n",
    "# the number of scales\n",
    "# 1 < J, default~=log_2(T)-3 for \"battle_lemarie\" wavelets\n",
    "\n",
    "# the choice of J is ruled by a tradeoff\n",
    "# 1. J should be large enough for the model to capture long-range dependencies\n",
    "# 2. J should be small enough for the largest-scale coefficients to be well-estimated\n",
    "\n",
    "# below:\n",
    "# J = log_2(T)-4: the low-pass wavelet support is of the order of 12% of the\n",
    "#       time-series size: long-range dependencies, if any, won't be captured well\n",
    "# J = log_2(T)-3: the low-pass wavelet support is of the order of 25%.\n",
    "#       Intuitively, the average <|x*\\phi(t)|^2> is thus made on 4 points.\n",
    "#       (Number of non-overlapping support intervals that can put on the time-series).\n",
    "# J = log_2(T)-2: the low-pass wavelet support is of the order of 50%.\n",
    "#       Intuitively, the average <|x*\\phi(t)|^2> is made on 2 points, which\n",
    "#       yields a large-variance estimator.\n",
    "\n",
    "T = 2048\n",
    "\n",
    "\n",
    "def get_support_size(filter, threshold=0.10):\n",
    "    threshold = filter.abs().max() * threshold\n",
    "    size = (filter.abs() > threshold).sum(-1)\n",
    "    idx_max = filter.abs().argmax(-1)\n",
    "    idces = torch.arange(idx_max - size // 2, idx_max + size // 2)\n",
    "    return size, idces\n",
    "\n",
    "\n",
    "J_choosen = int(np.log2(T)) - 3\n",
    "Js = [J_choosen - 1, J_choosen, J_choosen + 1]\n",
    "phis = [\n",
    "    get_wavelet_phi(T, J=J, Q=1, wav_type=\"battle_lemarie\", high_freq=0.425)[0]\n",
    "    for J in Js\n",
    "]\n",
    "freqs = torch.fft.fftfreq(T)\n",
    "\n",
    "################ plotting ####################################\n",
    "fig, axes = plt.subplots(len(Js), 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Low-pass filter (time domain)\")\n",
    "axes[-1].set_xlabel(\"$t$\")\n",
    "for i in range(len(Js)):\n",
    "    axes[i].axhline(0.0, color=\"black\", lw=0.4)\n",
    "    s, idces = get_support_size(phis[i])\n",
    "    print(s)\n",
    "    axes[i].axvspan(idces.min(), idces.max(), color=\"gray\", alpha=0.25)\n",
    "    if i < 2:\n",
    "        axes[i].set_xticklabels([])\n",
    "    axes[i].plot(phis[i].real, label=f\"J={Js[i]}\")\n",
    "    axes[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter 'Q'\n",
    "# the number of wavelets per scale\n",
    "# 1 <= Q, default=1\n",
    "\n",
    "# increasing Q has the following behavior depending on the wavelet\n",
    "# 1. for \"battle_lemarie\" wavelets, increasing Q will introduce intermediate\n",
    "# dilation steps: 2^(j/Q) from one filter to the other\n",
    "# 2. for \"morlet\" wavelets, increasing Q increases the frequency resolution of\n",
    "# each wavelet\n",
    "# (these two separate behaviors has nothing to do with the type of wavelet,\n",
    "# they are just a code artefact)\n",
    "\n",
    "# take Q>1 (with \"morlet\" wavelets) only if the time-series has non-trivial\n",
    "# structures which require better frequency resolution to be characterized\n",
    "\n",
    "T = 2048\n",
    "\n",
    "J = int(np.log2(T)) - 4\n",
    "Qs = [1, 2, 8]\n",
    "psis_hat_bl = [\n",
    "    get_wavelets_psi(T, J=J, Q=Q, wav_type=\"battle_lemarie\", high_freq=0.425)[1]\n",
    "    for Q in Qs\n",
    "]\n",
    "psis_hat_morlet = [\n",
    "    get_wavelets_psi(T, J=J, Q=Q, wav_type=\"morlet\", high_freq=0.425)[1] for Q in Qs\n",
    "]\n",
    "freqs = torch.fft.fftfreq(T)\n",
    "\n",
    "################ plotting ####################################\n",
    "fig, axes = plt.subplots(len(Qs), 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Battle-lemarie Wavelets (fourier domain)\")\n",
    "axes[-1].set_xlabel(\"$\\omega$\")\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "for i in range(len(Qs)):\n",
    "    if i < 2:\n",
    "        axes[i].set_xticklabels([])\n",
    "    for j, wav_hat in enumerate(psis_hat_bl[i]):\n",
    "        axes[i].plot(\n",
    "            torch.fft.fftshift(freqs),\n",
    "            torch.fft.fftshift(wav_hat, dim=-1).real.T,\n",
    "            color=colors[j // Qs[i]],\n",
    "        )\n",
    "    axes[i].set_ylabel(f\"Q={Qs[i]}\", fontsize=15)\n",
    "fig, axes = plt.subplots(len(Qs), 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Morlet Wavelets (fourier domain)\")\n",
    "axes[-1].set_xlabel(\"$\\omega$\")\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "for i in range(len(Qs)):\n",
    "    if i < 2:\n",
    "        axes[i].set_xticklabels([])\n",
    "    for j, wav_hat in enumerate(psis_hat_morlet[i]):\n",
    "        axes[i].plot(\n",
    "            torch.fft.fftshift(freqs),\n",
    "            torch.fft.fftshift(wav_hat, dim=-1).real.T,\n",
    "            color=colors[j // Qs[i]],\n",
    "        )\n",
    "    axes[i].set_ylabel(f\"Q={Qs[i]}\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generation of time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function: 'generate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed data\n",
    "data_snp = SPDaily()\n",
    "\n",
    "# generate data\n",
    "x_gen = generate(\n",
    "    x=data_snp.dlnx,\n",
    "    S=1,\n",
    "    model_type=\"scat_spectra\",\n",
    "    cache_path=None,  # provide a directory if you want to cache the generations\n",
    "    cuda=CUDA,  # you are strongly encouraged to use GPU if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 3))\n",
    "axes[0].set_title(\"Financial log-returns\", fontsize=20)\n",
    "axes[0].plot(data_snp.dts[:-1], data_snp.dlnx[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[0].set_ylabel(f\"S&P\", fontsize=15)\n",
    "axes[1].plot(data_snp.dts[:-1], x_gen[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[1].set_ylabel(f\"Model\", fontsize=15)\n",
    "for iax, ax in enumerate(axes):\n",
    "    if iax < axes.size - 1:\n",
    "        ax.set_xticklabels([])\n",
    "    ylim = 0.04\n",
    "    ax.set_ylim(-ylim, ylim)\n",
    "    ax.grid(True)\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of coefficients in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed data\n",
    "data_snp = SPDaily()\n",
    "\n",
    "x0 = np.random.randn(*data_snp.dlnx.shape)[:, None, :, :]\n",
    "\n",
    "# generate data with restricted model\n",
    "# the model associated to this generation imposes only the 'mean' and\n",
    "# the 'variance' coefficients (power-spectrum) it is thus a Gaussian model\n",
    "x_gen_1 = generate(\n",
    "    x=data_snp.dlnx,\n",
    "    x0=x0,\n",
    "    S=1,\n",
    "    model_type=\"scat_spectra\",\n",
    "    coeff_types=[\"mean\", \"variance\"],\n",
    "    cache_path=CACHE_PATH,\n",
    "    cuda=CUDA,\n",
    ")\n",
    "\n",
    "# generate data with restricted model\n",
    "# this model is non-Gaussian but does not capture long-range dependencies well\n",
    "x_gen_2 = generate(\n",
    "    x=data_snp.dlnx,\n",
    "    x0=x0,\n",
    "    S=1,\n",
    "    model_type=\"scat_spectra\",\n",
    "    coeff_types=[\"mean\", \"variance\", \"spars\"],\n",
    "    cache_path=CACHE_PATH,\n",
    "    cuda=CUDA,\n",
    ")\n",
    "\n",
    "# generate data with full model\n",
    "x_gen_full = generate(\n",
    "    x=data_snp.dlnx,\n",
    "    x0=x0,\n",
    "    S=1,\n",
    "    model_type=\"scat_spectra\",\n",
    "    cache_path=CACHE_PATH,\n",
    "    cuda=CUDA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 1, figsize=(10, 4))\n",
    "axes[0].set_title(\"Financial log-returns\", fontsize=20)\n",
    "axes[0].plot(data_snp.dts[:-1], data_snp.dlnx[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[0].set_ylabel(f\"S&P\", fontsize=15)\n",
    "axes[1].plot(data_snp.dts[:-1], x_gen_1[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[1].set_ylabel(f\"gen 1\", fontsize=15)\n",
    "axes[2].plot(data_snp.dts[:-1], x_gen_2[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[2].set_ylabel(f\"gen 2\", fontsize=15)\n",
    "axes[3].plot(data_snp.dts[:-1], x_gen_full[0, 0, :], lw=0.4, color=\"black\")\n",
    "axes[3].set_ylabel(f\"gen full\", fontsize=15)\n",
    "for iax, ax in enumerate(axes):\n",
    "    if iax < axes.size - 1:\n",
    "        ax.set_xticklabels([])\n",
    "    ylim = 0.04\n",
    "    ax.set_ylim(-ylim, ylim)\n",
    "    ax.grid(True)\n",
    "    ax.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation from adjusted representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed data\n",
    "data_snp = SPDaily()\n",
    "\n",
    "# estimate Scattering Spectra on observed data\n",
    "scat_snp = analyze(x=data_snp.dlnx, model_type=\"scat_spectra\", J=8, cuda=CUDA)\n",
    "\n",
    "# reference Scattering Spectra of white noise\n",
    "scat_ref = analyze(\n",
    "    x=np.random.randn(128, 1, data_snp.dlnx.shape[-1]),\n",
    "    model_type=\"scat_spectra\",\n",
    "    J=8,\n",
    "    cuda=CUDA,\n",
    ").mean_batch()\n",
    "\n",
    "\n",
    "def adjust_gaussianity(scat, scat_ref, lam=0.5):\n",
    "    scat_adj = scat.clone()\n",
    "    mask = scat_adj.eval(\"coeff_type=='spars'\")\n",
    "    # scat_adj.y[:,mask,:] = ((1 - lam) * scat_ref.y + lam * scat.y)[:,mask,:]\n",
    "    scat_adj.y[:, mask, :] = lam * scat.y[:, mask, :]\n",
    "    return scat_adj\n",
    "\n",
    "\n",
    "# change the estimated statistics e.g. change sparsity levels\n",
    "# lams = [1.0,1.5,2.0]\n",
    "lams = [1.0, 0.8, 0.6]\n",
    "print(lams)\n",
    "scats_adjusted = [adjust_gaussianity(scat_snp, scat_ref, lam) for lam in lams]\n",
    "\n",
    "axes = plot_dashboard(\n",
    "    scats_adjusted, labels=[f\"lam={lam:.2f}\" for lam in lams], figsize=(12, 6)\n",
    ")\n",
    "axes[1, 0].legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the same gaussian white noise\n",
    "x0 = np.random.randn(*data_snp.dlnx.shape)[:, None, :, :]\n",
    "\n",
    "# generate data based on the adjusted statistics\n",
    "x_gen_adjusted = []\n",
    "for ilam, scat_adj in enumerate(scats_adjusted):\n",
    "    exp_name = f\"lam={lams[ilam]}\"\n",
    "    print(exp_name)\n",
    "    x_gen_adj = generate(\n",
    "        Rx=scat_adj,\n",
    "        x0=x0,\n",
    "        shape=data_snp.dlnx.shape,\n",
    "        model_type=\"scat_spectra\",\n",
    "        J=8,\n",
    "        cache_path=CACHE_PATH,\n",
    "        exp_name=exp_name,\n",
    "        cuda=False,\n",
    "    )\n",
    "    x_gen_adjusted.append(x_gen_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "fig, axes = plt.subplots(len(x_gen_adjusted), 1, figsize=(10, 4))\n",
    "for iax, x_gen_adj in enumerate(x_gen_adjusted):\n",
    "    axes[iax].plot(data_snp.dts[:-1], x_gen_adj[0, 0, :], lw=0.4, color=\"black\")\n",
    "    axes[iax].set_ylabel(f\"lam={lams[iax]}\", fontsize=15)\n",
    "for iax, ax in enumerate(axes):\n",
    "    if iax < axes.size - 1:\n",
    "        ax.set_xticklabels([])\n",
    "    ylim = 0.04\n",
    "    ax.set_ylim(-ylim, ylim)\n",
    "    ax.grid(True)\n",
    "    ax.set_yticklabels([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scatspectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
